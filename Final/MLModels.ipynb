{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import scipy.stats as stats\n",
    "import scipy.signal as signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    \n",
    "    for column in ['x', 'y', 'z']:\n",
    "        df[column] = (df[column] - df[column].mean()) / df[column].std()\n",
    "    df = pd.DataFrame(df[['x', 'y', 'z']])\n",
    "    return df\n",
    "\n",
    "def segment(df, window_size, step_size):\n",
    "    segments = []\n",
    "    for start in range(0, len(df) - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        segment = df.iloc[start:end]\n",
    "        segments.append(segment)\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_activities(window_size=32, step_size=16):\n",
    "    # window_size =   # 2.5 seconds\n",
    "    # step_size = 20  # 75% overlap\n",
    "\n",
    "    activities_path = 'Final/Activity' #CHANGE THIS BASED OFF FILE PATH\n",
    "    activity_segments = {}\n",
    "\n",
    "    # Iterate over each activity's folder\n",
    "    for activity_name in os.listdir(activities_path):\n",
    "        # print(activity_name)\n",
    "        activity_folder = os.path.join(activities_path, activity_name)\n",
    "        if os.path.isdir(activity_folder):\n",
    "            # Store segments for each activity\n",
    "            activity_segments[activity_name] = []\n",
    "            \n",
    "            # Iterate over each CSV file within the activity's folder\n",
    "            for filename in os.listdir(activity_folder):\n",
    "                if filename.endswith('.csv'):\n",
    "                    file_path = os.path.join(activity_folder, filename)\n",
    "                    \n",
    "                    # Read  CSV file\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    \n",
    "                    # Normalize data\n",
    "                    df_normalized = normalize(df)\n",
    "                    \n",
    "                    # Segment the data using a rolling window\n",
    "                    segments = segment(df_normalized, window_size, step_size)\n",
    "                    \n",
    "                    # Append the segments to the activity's list\n",
    "                    activity_segments[activity_name].extend(segments)\n",
    "    return activity_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_lstm(activity_segments):\n",
    "    X, y = [], []\n",
    "\n",
    "\n",
    "    # Convert the segments into a suitable format for training\n",
    "    for activity_name, segments in activity_segments.items():\n",
    "        for segment in segments:\n",
    "            X.append(segment.to_numpy())  # Assuming segment is a pandas DataFrame\n",
    "            y.append(activity_name)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    # print(\"segments in suitable format\")\n",
    "\n",
    "\n",
    "    # Encode the activity labels into integers\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    # print(\"labels encoded\")\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the LSTM model\n",
    "    model = Sequential([\n",
    "        LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "        LSTM(64),\n",
    "        Dense(len(le.classes_), activation='softmax')\n",
    "    ])\n",
    "    # print(\"comiling model\")\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # print(\"training model\")\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.evaluate(X_test, y_test)\n",
    "    # return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_rf(activity_segments):\n",
    "    X, y = [], []\n",
    "\n",
    "\n",
    "    # Convert the segments into a suitable format for training\n",
    "    for activity_name, segments in activity_segments.items():\n",
    "        for segment in segments:\n",
    "            X.append(segment.to_numpy())  # Assuming segment is a pandas DataFrame\n",
    "            y.append(activity_name)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    print(\"segments in suitable format\")\n",
    "\n",
    "\n",
    "    # Encode the activity labels into integers\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    print(\"labels encoded\")\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "    #reshape for rf model\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "    #model stuff\n",
    "    # Define the Random Forest model\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    print(\"training model\")\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(f\"Model accuracy: {accuracy}\")\n",
    "\n",
    "    # return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_SVM(activity_segments):\n",
    "    X, y = [], []\n",
    "\n",
    "    # Convert the segments into a suitable format for training\n",
    "    for activity_name, segments in activity_segments.items():\n",
    "        for segment in segments:\n",
    "            feature_vector = segment.to_numpy().flatten()\n",
    "            X.append(feature_vector)\n",
    "            y.append(activity_name)\n",
    "    print(\"segments in suitable format\")\n",
    "\n",
    "    # Encode the activity labels into integers\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    print(\"labels encoded\")\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Change labels to 1 and -1\n",
    "    y_train = np.where(y_train > 0, 1, -1)\n",
    "    y_test = np.where(y_test > 0, 1, -1)\n",
    "\n",
    "    # Define the SVM model by Tensorflow\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(1, input_shape=(X_train_scaled.shape[1],))\n",
    "    ])\n",
    "\n",
    "    # Custom hinge loss\n",
    "    def hinge_loss(y_true, y_pred):\n",
    "        return tf.reduce_mean(tf.maximum(1 - y_true * y_pred, 0))\n",
    "\n",
    "    model.compile(optimizer='sgd', loss=hinge_loss, metrics=['accuracy'])\n",
    "\n",
    "    print(\"compiled model\\nTraining Model\")\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.evaluate(X_test_scaled, y_test)\n",
    "    print(model.evaluate(X_test_scaled, y_test))\n",
    "    \n",
    "    # return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_XGB(activity_segments):\n",
    "    X, y = [], []\n",
    "\n",
    "\n",
    "    # Convert the segments into a suitable format for training\n",
    "    for activity_name, segments in activity_segments.items():\n",
    "        for segment in segments:\n",
    "            X.append(segment.to_numpy())  # Assuming segment is a pandas DataFrame\n",
    "            y.append(activity_name)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    print(\"segments in suitable format\")\n",
    "\n",
    "\n",
    "    # Encode the activity labels into integers\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    print(\"labels encoded\")\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2)\n",
    "    print('X_train:', X_train.shape)\n",
    "    print('y_train:', y_train.shape)\n",
    "    \n",
    "    \n",
    "    # Convert data to DMatrix format for XGBoost\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    # Define parameters for XGBoost\n",
    "    params = {\n",
    "        'objective': 'multi:softmax',  # Multi-class classification\n",
    "        'num_class': 34,                # Number of classes\n",
    "        'eval_metric': 'merror',         # Evaluation metric: multi-class classification error\n",
    "        'learning_rate': 0.2, \n",
    "        'max_depth': 6, \n",
    "        'n_estimators': 200, \n",
    "        'subsample': 1.0\n",
    "    }\n",
    "\n",
    "# **params\n",
    "    xgb_classifier = xgb.XGBClassifier(**params)\n",
    "    xgb_classifier.fit(X_train, y_train)\n",
    "    # Predict on the test data\n",
    "    y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Test Accuracy: {accuracy}')\n",
    "    \n",
    "    # return xgb_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_lgbm(activity_segments):\n",
    "    X, y = [], []\n",
    "\n",
    "\n",
    "    # Convert the segments into a suitable format for training\n",
    "    for activity_name, segments in activity_segments.items():\n",
    "        for segment in segments:\n",
    "            X.append(segment.to_numpy())  # Assuming segment is a pandas DataFrame\n",
    "            y.append(activity_name)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    print(\"segments in suitable format\")\n",
    "\n",
    "\n",
    "    # Encode the activity labels into integers\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    print(\"labels encoded\")\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "    print('X_train:', X_train.shape)\n",
    "    print('y_train:', y_train.shape)\n",
    "\n",
    "    # Model Training\n",
    "    clf = LGBMClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    # return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NO FILTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:2  Window:32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep_sizes[index_step][step]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  Window:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwindow_sizes[step]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)       \n\u001b[0;32m---> 10\u001b[0m     activity_segments \u001b[38;5;241m=\u001b[39m \u001b[43msegment_activities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex_step\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished  Window:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwindow_sizes[step]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Segmentation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTARTING LSTM MODEL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 28\u001b[0m, in \u001b[0;36msegment_activities\u001b[0;34m(window_size, step_size)\u001b[0m\n\u001b[1;32m     25\u001b[0m df_normalized \u001b[38;5;241m=\u001b[39m normalize(df)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Segment the data using a rolling window\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m segments \u001b[38;5;241m=\u001b[39m \u001b[43msegment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Append the segments to the activity's list\u001b[39;00m\n\u001b[1;32m     31\u001b[0m activity_segments[activity_name]\u001b[38;5;241m.\u001b[39mextend(segments)\n",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m, in \u001b[0;36msegment\u001b[0;34m(df, window_size, step_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df) \u001b[38;5;241m-\u001b[39m window_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, step_size):\n\u001b[1;32m     11\u001b[0m     end \u001b[38;5;241m=\u001b[39m start \u001b[38;5;241m+\u001b[39m window_size\n\u001b[0;32m---> 12\u001b[0m     segment \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m     segments\u001b[38;5;241m.\u001b[39mappend(segment)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m segments\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1070\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1072\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m-> 1073\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexing.py:1602\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1596\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\n\u001b[1;32m   1597\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDataFrame indexer is not allowed for .iloc\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1598\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider using .loc for automatic alignment.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1599\u001b[0m     )\n\u001b[1;32m   1601\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n\u001b[0;32m-> 1602\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_slice_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1604\u001b[0m \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   1605\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexing.py:1638\u001b[0m, in \u001b[0;36m_iLocIndexer._get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1636\u001b[0m labels \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1637\u001b[0m labels\u001b[39m.\u001b[39m_validate_positional_slice(slice_obj)\n\u001b[0;32m-> 1638\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_slice(slice_obj, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py:4105\u001b[0m, in \u001b[0;36mNDFrame._slice\u001b[0;34m(self, slobj, axis)\u001b[0m\n\u001b[1;32m   4103\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(slobj, \u001b[39mslice\u001b[39m), \u001b[39mtype\u001b[39m(slobj)\n\u001b[1;32m   4104\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_block_manager_axis(axis)\n\u001b[0;32m-> 4105\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_constructor(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mget_slice(slobj, axis\u001b[39m=\u001b[39;49maxis))\n\u001b[1;32m   4106\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m)\n\u001b[1;32m   4108\u001b[0m \u001b[39m# this could be a view\u001b[39;00m\n\u001b[1;32m   4109\u001b[0m \u001b[39m# but only in a single-dtyped view sliceable case\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:631\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (BlockManager, ArrayManager)):\n\u001b[1;32m    627\u001b[0m     \u001b[39m# first check if a Manager is passed without any other arguments\u001b[39;00m\n\u001b[1;32m    628\u001b[0m     \u001b[39m# -> use fastpath (without checking Manager type)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m copy:\n\u001b[1;32m    630\u001b[0m         \u001b[39m# GH#33357 fastpath\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m         NDFrame\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, data)\n\u001b[1;32m    632\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    634\u001b[0m manager \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39m\u001b[39mmode.data_manager\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py:275\u001b[0m, in \u001b[0;36mNDFrame.__init__\u001b[0;34m(self, data, copy, attrs)\u001b[0m\n\u001b[1;32m    273\u001b[0m     attrs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(attrs)\n\u001b[1;32m    274\u001b[0m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_attrs\u001b[39m\u001b[39m\"\u001b[39m, attrs)\n\u001b[0;32m--> 275\u001b[0m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_flags\u001b[39m\u001b[39m\"\u001b[39m, Flags(\u001b[39mself\u001b[39;49m, allows_duplicate_labels\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/flags.py:51\u001b[0m, in \u001b[0;36mFlags.__init__\u001b[0;34m(self, obj, allows_duplicate_labels)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, obj, \u001b[39m*\u001b[39m, allows_duplicate_labels) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_allows_duplicate_labels \u001b[39m=\u001b[39m allows_duplicate_labels\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj \u001b[39m=\u001b[39m weakref\u001b[39m.\u001b[39;49mref(obj)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "window_sizes = [32, 96, 160]  # 1, 1.5, and 2 seconds\n",
    "step_sizes_16 = [2, 6, 10]  # 1/16 overlap for each window size\n",
    "step_sizes_8 = [4, 12, 20]  # 1/8 overlap for each window size\n",
    "step_sizes_4 = [8, 24, 40]  # 1/4 overlap for each window size\n",
    "step_sizes = [step_sizes_16 ,step_sizes_8, step_sizes_4]\n",
    "\n",
    "for index_step in range(3):\n",
    "    for step in range(3):\n",
    "        print(f\"Step:{step_sizes[index_step][step]}  Window:{window_sizes[step]}\")       \n",
    "        activity_segments = segment_activities(window_sizes[step], step_sizes[index_step][step])\n",
    "        print(f\"Finished  Window:{window_sizes[step]} Segmentation\")\n",
    "        print(f\"STARTING LSTM MODEL\")\n",
    "        fit_model_lstm(activity_segments)\n",
    "        print(f\"STARTING RANDOM FOREST MODEL\")\n",
    "        fit_model_rf(activity_segments)\n",
    "        print(f\"STARTING XGB MODEL\")\n",
    "        fit_model_XGB(activity_segments)\n",
    "        print(f\"STARTING SVM MODEL\")\n",
    "        fit_model_SVM(activity_segments)\n",
    "        print(f\"STARTING LGBM MODEL\")\n",
    "        fit_model_lgbm(activity_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEAN FILTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_mean(input_df):\n",
    "    input_x = np.array(input_df.loc[:, \"x\"])\n",
    "    input_y = np.array(input_df.loc[:, \"y\"])\n",
    "    input_z = np.array(input_df.loc[:, \"z\"])\n",
    "\n",
    "    return np.mean(input_x), np.mean(input_y), np.mean(input_z)\n",
    "\n",
    "def normalize(df):\n",
    "    \n",
    "    x, y, z = windowed_mean(df)\n",
    "    df = pd.DataFrame(df[['x', 'y', 'z']])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [32, 96, 160]  # 1, 1.5, and 2 seconds\n",
    "step_sizes_16 = [2, 6, 10]  # 1/16 overlap for each window size\n",
    "step_sizes_8 = [4, 12, 20]  # 1/8 overlap for each window size\n",
    "step_sizes_4 = [8, 24, 40]  # 1/4 overlap for each window size\n",
    "step_sizes = [step_sizes_16 ,step_sizes_8, step_sizes_4]\n",
    "\n",
    "for index_step in range(3):\n",
    "    for step in range(3):\n",
    "        print(f\"Step:{step_sizes[index_step][step]}  Window:{window_sizes[step]}\")       \n",
    "        activity_segments = segment_activities(window_sizes[step], step_sizes[index_step][step])\n",
    "        print(f\"Finished  Window:{window_sizes[step]} Segmentation\")\n",
    "        print(f\"STARTING LSTM MODEL\")\n",
    "        fit_model_lstm(activity_segments)\n",
    "        print(f\"STARTING RANDOM FOREST MODEL\")\n",
    "        fit_model_rf(activity_segments)\n",
    "        print(f\"STARTING XGB MODEL\")\n",
    "        fit_model_XGB(activity_segments)\n",
    "        print(f\"STARTING SVM MODEL\")\n",
    "        fit_model_SVM(activity_segments)\n",
    "        print(f\"STARTING LGBM MODEL\")\n",
    "        fit_model_lgbm(activity_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STD DEV FITLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_std_dev(input_df):\n",
    "    input_x = np.array(input_df.loc[:, \"x\"])\n",
    "    input_y = np.array(input_df.loc[:, \"y\"])\n",
    "    input_z = np.array(input_df.loc[:, \"z\"])\n",
    "\n",
    "    return np.std(input_x), np.std(input_y), np.std(input_z)\n",
    "\n",
    "def normalize(df):\n",
    "    \n",
    "    x, y, z = windowed_std_dev(df)\n",
    "    df = pd.DataFrame(df[['x', 'y', 'z']])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [32, 96, 160]  # 1, 1.5, and 2 seconds\n",
    "step_sizes_16 = [2, 6, 10]  # 1/16 overlap for each window size\n",
    "step_sizes_8 = [4, 12, 20]  # 1/8 overlap for each window size\n",
    "step_sizes_4 = [8, 24, 40]  # 1/4 overlap for each window size\n",
    "step_sizes = [step_sizes_16 ,step_sizes_8, step_sizes_4]\n",
    "\n",
    "for index_step in range(3):\n",
    "    for step in range(3):\n",
    "        print(f\"Step:{step_sizes[index_step][step]}  Window:{window_sizes[step]}\")       \n",
    "        activity_segments = segment_activities(window_sizes[step], step_sizes[index_step][step])\n",
    "        print(f\"Finished  Window:{window_sizes[step]} Segmentation\")\n",
    "        print(f\"STARTING LSTM MODEL\")\n",
    "        fit_model_lstm(activity_segments)\n",
    "        print(f\"STARTING RANDOM FOREST MODEL\")\n",
    "        fit_model_rf(activity_segments)\n",
    "        print(f\"STARTING XGB MODEL\")\n",
    "        fit_model_XGB(activity_segments)\n",
    "        print(f\"STARTING SVM MODEL\")\n",
    "        fit_model_SVM(activity_segments)\n",
    "        print(f\"STARTING LGBM MODEL\")\n",
    "        fit_model_lgbm(activity_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKEWNESS FILTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_skew(input_df):\n",
    "    input_x = np.array(input_df.loc[:, \"x\"])\n",
    "    input_y = np.array(input_df.loc[:, \"y\"])\n",
    "    input_z = np.array(input_df.loc[:, \"z\"])\n",
    "\n",
    "    return stats.skew(input_x), stats.skew(input_y), stats.skew(input_z)\n",
    "\n",
    "def normalize(df):\n",
    "    \n",
    "    x, y, z = windowed_skew(df)\n",
    "    df = pd.DataFrame(df[['x', 'y', 'z']])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [32, 96, 160]  # 1, 1.5, and 2 seconds\n",
    "step_sizes_16 = [2, 6, 10]  # 1/16 overlap for each window size\n",
    "step_sizes_8 = [4, 12, 20]  # 1/8 overlap for each window size\n",
    "step_sizes_4 = [8, 24, 40]  # 1/4 overlap for each window size\n",
    "step_sizes = [step_sizes_16 ,step_sizes_8, step_sizes_4]\n",
    "\n",
    "for index_step in range(3):\n",
    "    for step in range(3):\n",
    "        print(f\"Step:{step_sizes[index_step][step]}  Window:{window_sizes[step]}\")       \n",
    "        activity_segments = segment_activities(window_sizes[step], step_sizes[index_step][step])\n",
    "        print(f\"Finished  Window:{window_sizes[step]} Segmentation\")\n",
    "        print(f\"STARTING LSTM MODEL\")\n",
    "        fit_model_lstm(activity_segments)\n",
    "        print(f\"STARTING RANDOM FOREST MODEL\")\n",
    "        fit_model_rf(activity_segments)\n",
    "        print(f\"STARTING XGB MODEL\")\n",
    "        fit_model_XGB(activity_segments)\n",
    "        print(f\"STARTING SVM MODEL\")\n",
    "        fit_model_SVM(activity_segments)\n",
    "        print(f\"STARTING LGBM MODEL\")\n",
    "        fit_model_lgbm(activity_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kurtosis Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_kurtosis(input_df):\n",
    "    input_x = np.array(input_df.loc[:, \"x\"])\n",
    "    input_y = np.array(input_df.loc[:, \"y\"])\n",
    "    input_z = np.array(input_df.loc[:, \"z\"])\n",
    "\n",
    "    return stats.kurtosis(input_x), stats.kurtosis(input_y), stats.kurtosis(input_z)\n",
    "\n",
    "def normalize(df):\n",
    "    \n",
    "    x, y, z = windowed_kurtosis(df)\n",
    "    df = pd.DataFrame(df[['x', 'y', 'z']])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [32, 96, 160]  # 1, 1.5, and 2 seconds\n",
    "step_sizes_16 = [2, 6, 10]  # 1/16 overlap for each window size\n",
    "step_sizes_8 = [4, 12, 20]  # 1/8 overlap for each window size\n",
    "step_sizes_4 = [8, 24, 40]  # 1/4 overlap for each window size\n",
    "step_sizes = [step_sizes_16 ,step_sizes_8, step_sizes_4]\n",
    "\n",
    "for index_step in range(3):\n",
    "    for step in range(3):\n",
    "        print(f\"Step:{step_sizes[index_step][step]}  Window:{window_sizes[step]}\")       \n",
    "        activity_segments = segment_activities(window_sizes[step], step_sizes[index_step][step])\n",
    "        print(f\"Finished  Window:{window_sizes[step]} Segmentation\")\n",
    "        print(f\"STARTING LSTM MODEL\")\n",
    "        fit_model_lstm(activity_segments)\n",
    "        print(f\"STARTING RANDOM FOREST MODEL\")\n",
    "        fit_model_rf(activity_segments)\n",
    "        print(f\"STARTING XGB MODEL\")\n",
    "        fit_model_XGB(activity_segments)\n",
    "        print(f\"STARTING SVM MODEL\")\n",
    "        fit_model_SVM(activity_segments)\n",
    "        print(f\"STARTING LGBM MODEL\")\n",
    "        fit_model_lgbm(activity_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Crossing Rate Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_zcr(input_df):\n",
    "\n",
    "    def compute_zcr(input_arr):\n",
    "        my_array = np.array(input_arr)\n",
    "        return float(((((my_array[:-1] * my_array[1:]) < 0).sum())/len(input_arr)))\n",
    "\n",
    "    input_x = np.array(input_df.loc[:, \"x\"])\n",
    "    input_y = np.array(input_df.loc[:, \"y\"])\n",
    "    input_z = np.array(input_df.loc[:, \"z\"])\n",
    "\n",
    "    return compute_zcr(input_x), compute_zcr(input_y), compute_zcr(input_z)\n",
    "\n",
    "def normalize(df):\n",
    "    \n",
    "    x, y, z = windowed_zcr(df)\n",
    "    df = pd.DataFrame(df[['x', 'y', 'z']])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [32, 96, 160]  # 1, 1.5, and 2 seconds\n",
    "step_sizes_16 = [2, 6, 10]  # 1/16 overlap for each window size\n",
    "step_sizes_8 = [4, 12, 20]  # 1/8 overlap for each window size\n",
    "step_sizes_4 = [8, 24, 40]  # 1/4 overlap for each window size\n",
    "step_sizes = [step_sizes_16 ,step_sizes_8, step_sizes_4]\n",
    "\n",
    "for index_step in range(3):\n",
    "    for step in range(3):\n",
    "        print(f\"Step:{step_sizes[index_step][step]}  Window:{window_sizes[step]}\")       \n",
    "        activity_segments = segment_activities(window_sizes[step], step_sizes[index_step][step])\n",
    "        print(f\"Finished  Window:{window_sizes[step]} Segmentation\")\n",
    "        print(f\"STARTING LSTM MODEL\")\n",
    "        fit_model_lstm(activity_segments)\n",
    "        print(f\"STARTING RANDOM FOREST MODEL\")\n",
    "        fit_model_rf(activity_segments)\n",
    "        print(f\"STARTING XGB MODEL\")\n",
    "        fit_model_XGB(activity_segments)\n",
    "        print(f\"STARTING SVM MODEL\")\n",
    "        fit_model_SVM(activity_segments)\n",
    "        print(f\"STARTING LGBM MODEL\")\n",
    "        fit_model_lgbm(activity_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dominant Frequency Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dom_f(input_df):\n",
    "\n",
    "    def compute(input_arr):\n",
    "        frequency_spectrum = np.fft.fft(input_arr)\n",
    "        dom = frequency_spectrum[np.argmax(frequency_spectrum)]\n",
    "        return dom\n",
    "    input_x = np.array(input_df.loc[:, \"x\"])\n",
    "    input_y = np.array(input_df.loc[:, \"y\"])\n",
    "    input_z = np.array(input_df.loc[:, \"z\"])\n",
    "\n",
    "    return compute(input_x), compute(input_y), compute(input_z)\n",
    "\n",
    "def normalize(df):\n",
    "    \n",
    "    x, y, z = dom_f(df)\n",
    "    df = pd.DataFrame(df[['x', 'y', 'z']])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [32, 96, 160]  # 1, 1.5, and 2 seconds\n",
    "step_sizes_16 = [2, 6, 10]  # 1/16 overlap for each window size\n",
    "step_sizes_8 = [4, 12, 20]  # 1/8 overlap for each window size\n",
    "step_sizes_4 = [8, 24, 40]  # 1/4 overlap for each window size\n",
    "step_sizes = [step_sizes_16 ,step_sizes_8, step_sizes_4]\n",
    "\n",
    "for index_step in range(3):\n",
    "    for step in range(3):\n",
    "        print(f\"Step:{step_sizes[index_step][step]}  Window:{window_sizes[step]}\")       \n",
    "        activity_segments = segment_activities(window_sizes[step], step_sizes[index_step][step])\n",
    "        print(f\"Finished  Window:{window_sizes[step]} Segmentation\")\n",
    "        print(f\"STARTING LSTM MODEL\")\n",
    "        fit_model_lstm(activity_segments)\n",
    "        print(f\"STARTING RANDOM FOREST MODEL\")\n",
    "        fit_model_rf(activity_segments)\n",
    "        print(f\"STARTING XGB MODEL\")\n",
    "        fit_model_XGB(activity_segments)\n",
    "        print(f\"STARTING SVM MODEL\")\n",
    "        fit_model_SVM(activity_segments)\n",
    "        print(f\"STARTING LGBM MODEL\")\n",
    "        fit_model_lgbm(activity_segments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
