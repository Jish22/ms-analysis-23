{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    \n",
    "    for column in ['x', 'y', 'z']:\n",
    "        df[column] = (df[column] - df[column].mean()) / df[column].std()\n",
    "    df = pd.DataFrame(df[['x', 'y', 'z']])\n",
    "    return df\n",
    "\n",
    "def segment(df, window_size, step_size):\n",
    "    segments = []\n",
    "    for start in range(0, len(df) - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "\n",
    "        \\\n",
    "        segment = df.iloc[start:end]\n",
    "        segments.append(segment)\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_activities(window_size=32, step_size=16):\n",
    "    # window_size = 160  # 2.5 seconds\n",
    "    # step_size = 20  # 75% overlap\n",
    "\n",
    "    activities_path = 'Activity'\n",
    "    activity_segments = {}\n",
    "\n",
    "    # Iterate over each activity's folder\n",
    "    for activity_name in os.listdir(activities_path):\n",
    "        print(activity_name)\n",
    "        activity_folder = os.path.join(activities_path, activity_name)\n",
    "        if os.path.isdir(activity_folder):\n",
    "            # Store segments for each activity\n",
    "            activity_segments[activity_name] = []\n",
    "            \n",
    "            # Iterate over each CSV file within the activity's folder\n",
    "            for filename in os.listdir(activity_folder):\n",
    "                if filename.endswith('.csv'):\n",
    "                    file_path = os.path.join(activity_folder, filename)\n",
    "                    \n",
    "                    # Read  CSV file\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    \n",
    "                    # Normalize data\n",
    "                    df_normalized = normalize(df)\n",
    "                    \n",
    "                    # Segment the data using a rolling window\n",
    "                    segments = segment(df_normalized, window_size, step_size)\n",
    "                    \n",
    "                    # Append the segments to the activity's list\n",
    "                    activity_segments[activity_name].extend(segments)\n",
    "    return activity_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(activity_segments):\n",
    "    X, y = [], []\n",
    "\n",
    "\n",
    "    # Convert the segments into a suitable format for training\n",
    "    for activity_name, segments in activity_segments.items():\n",
    "        for segment in segments:\n",
    "            X.append(segment.to_numpy())  # Assuming segment is a pandas DataFrame\n",
    "            y.append(activity_name)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    print(\"segments in suitable format\")\n",
    "\n",
    "\n",
    "    # Encode the activity labels into integers\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    print(\"labels encoded\")\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the LSTM model\n",
    "    model = Sequential([\n",
    "        LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "        LSTM(64),\n",
    "        Dense(len(le.classes_), activation='softmax')\n",
    "    ])\n",
    "    print(\"comiling model\")\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print(\"training model\")\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.evaluate(X_test, y_test)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Second Window, 1 Second Overlap Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segments in suitable format\n",
      "segments encoded\n",
      "comiling model\n",
      "training model\n",
      "Epoch 1/10\n",
      "13943/13943 [==============================] - 1589s 114ms/step - loss: 2.0645 - accuracy: 0.3276 - val_loss: 1.5044 - val_accuracy: 0.4773\n",
      "Epoch 2/10\n",
      "13943/13943 [==============================] - 1532s 110ms/step - loss: 1.2374 - accuracy: 0.5534 - val_loss: 1.0387 - val_accuracy: 0.6173\n",
      "Epoch 3/10\n",
      "13943/13943 [==============================] - 1569s 113ms/step - loss: 0.9156 - accuracy: 0.6645 - val_loss: 0.8274 - val_accuracy: 0.6926\n",
      "Epoch 4/10\n",
      "13943/13943 [==============================] - 1534s 110ms/step - loss: 0.7488 - accuracy: 0.7198 - val_loss: 0.6891 - val_accuracy: 0.7434\n",
      "Epoch 5/10\n",
      "13943/13943 [==============================] - 8596s 617ms/step - loss: 0.6303 - accuracy: 0.7621 - val_loss: 0.6068 - val_accuracy: 0.7726\n",
      "Epoch 6/10\n",
      "13943/13943 [==============================] - 1567s 112ms/step - loss: 0.5448 - accuracy: 0.7908 - val_loss: 0.5200 - val_accuracy: 0.8022\n",
      "Epoch 7/10\n",
      "13943/13943 [==============================] - 1546s 111ms/step - loss: 0.4942 - accuracy: 0.8089 - val_loss: 0.5010 - val_accuracy: 0.8071\n",
      "Epoch 8/10\n",
      "13943/13943 [==============================] - 1493s 107ms/step - loss: 0.4457 - accuracy: 0.8257 - val_loss: 0.5502 - val_accuracy: 0.7927\n",
      "Epoch 9/10\n",
      "13943/13943 [==============================] - 1425s 102ms/step - loss: 0.4085 - accuracy: 0.8400 - val_loss: 0.3961 - val_accuracy: 0.8463\n",
      "Epoch 10/10\n",
      "13943/13943 [==============================] - 1527s 109ms/step - loss: 0.4435 - accuracy: 0.8283 - val_loss: 0.4971 - val_accuracy: 0.8167\n",
      "4358/4358 [==============================] - 141s 32ms/step - loss: 0.4904 - accuracy: 0.8196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4904477298259735, 0.8195797204971313]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##new Method\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "\n",
    "# Convert the segments into a suitable format for training\n",
    "for activity_name, segments in activity_segments.items():\n",
    "    for segment in segments:\n",
    "        X.append(segment.to_numpy())  # Assuming segment is a pandas DataFrame\n",
    "        y.append(activity_name)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(\"segments in suitable format\")\n",
    "\n",
    "\n",
    "# Encode the activity labels into integers\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "print(\"labels encoded\")\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "    LSTM(64),\n",
    "    Dense(len(le.classes_), activation='softmax')\n",
    "])\n",
    "print(\"comiling model\")\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"training model\")\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFT Data 5 Second Window, 1 Second Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segments in suitable format\n",
      "Applied FFT\n",
      "encoded labels\n",
      "compiled model\n",
      "Training Model\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.fft import fft\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def apply_fft(segment):\n",
    "    # Apply FFT and calculate the magnitude\n",
    "    fft_values = fft(segment)\n",
    "    magnitude = np.abs(fft_values)\n",
    "    return magnitude\n",
    "\n",
    "# Assuming 'activity_segments' is a dictionary with the structure mentioned earlier\n",
    "X_fft = []  # FFT features\n",
    "y = []  # Labels\n",
    "\n",
    "for activity_name, segments in activity_segments.items():\n",
    "    for segment in segments:\n",
    "        # Assuming each segment is a pandas DataFrame with 'x', 'y', 'z' columns\n",
    "        segment_fft = np.vstack([apply_fft(segment[col]) for col in ['x', 'y', 'z']]).T  # Apply FFT to each axis and transpose\n",
    "        X_fft.append(segment_fft)\n",
    "        y.append(activity_name)\n",
    "\n",
    "X_fft = np.array(X_fft, dtype=object)\n",
    "y = np.array(y)\n",
    "print(\"segments in suitable format\\nApplied FFT\")\n",
    "\n",
    "# Encode the activity labels into integers\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "print(\"encoded labels\")\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fft, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Adjusting input shapes for LSTM based on FFT features\n",
    "input_shape = (X_train[0].shape[0], X_train[0].shape[1])\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=input_shape, return_sequences=True),\n",
    "    LSTM(64),\n",
    "    Dense(len(le.classes_), activation='softmax')\n",
    "])\n",
    "print(\"compiled model\\nTraining Model\")\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Since the datasets can have variable lengths due to FFT, use a generator or pad sequences for batching\n",
    "# Example code for model training and evaluation is omitted due to complexity around handling variable input lengths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded the data\n",
      "training and testing data\n",
      "compiled model\n",
      "training model\n",
      "Epoch 1/10\n",
      "13943/13943 [==============================] - 1511s 108ms/step - loss: 1.8652 - accuracy: 0.3859 - val_loss: 1.6013 - val_accuracy: 0.4551\n",
      "Epoch 2/10\n",
      "13943/13943 [==============================] - 1526s 109ms/step - loss: 1.4807 - accuracy: 0.4891 - val_loss: 1.3956 - val_accuracy: 0.5121\n",
      "Epoch 3/10\n",
      "13943/13943 [==============================] - 1439s 103ms/step - loss: 1.2980 - accuracy: 0.5393 - val_loss: 1.2635 - val_accuracy: 0.5506\n",
      "Epoch 4/10\n",
      "13943/13943 [==============================] - 1598s 115ms/step - loss: 1.1838 - accuracy: 0.5724 - val_loss: 1.1821 - val_accuracy: 0.5701\n",
      "Epoch 5/10\n",
      "13943/13943 [==============================] - 1576s 113ms/step - loss: 1.1060 - accuracy: 0.5946 - val_loss: 1.1134 - val_accuracy: 0.5917\n",
      "Epoch 6/10\n",
      "13943/13943 [==============================] - 1494s 107ms/step - loss: 1.0490 - accuracy: 0.6104 - val_loss: 1.0971 - val_accuracy: 0.5957\n",
      "Epoch 7/10\n",
      "13943/13943 [==============================] - 1621s 116ms/step - loss: 1.0082 - accuracy: 0.6226 - val_loss: 1.0362 - val_accuracy: 0.6148\n",
      "Epoch 8/10\n",
      "13943/13943 [==============================] - 1627s 117ms/step - loss: 0.9725 - accuracy: 0.6342 - val_loss: 1.0205 - val_accuracy: 0.6215\n",
      "Epoch 9/10\n",
      "13943/13943 [==============================] - 1605s 115ms/step - loss: 0.9471 - accuracy: 0.6413 - val_loss: 0.9972 - val_accuracy: 0.6268\n",
      "Epoch 10/10\n",
      "13943/13943 [==============================] - 1540s 110ms/step - loss: 0.9211 - accuracy: 0.6496 - val_loss: 0.9840 - val_accuracy: 0.6316\n",
      "4358/4358 [==============================] - 148s 34ms/step - loss: 0.9762 - accuracy: 0.6318\n",
      "Test Loss: 0.976159393787384, Test Accuracy: 0.6317578554153442\n"
     ]
    }
   ],
   "source": [
    "# Pad sequences to ensure uniform input size for LSTM\n",
    "# Find the longest sequence\n",
    "max_length = max(len(sample) for sample in X_fft)\n",
    "\n",
    "# Pad all sequences to the length of the longest sequence\n",
    "X_fft_padded = pad_sequences(X_fft, maxlen=max_length, dtype='float32', padding='post')\n",
    "print(\"padded the data\")\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fft_padded, y_encoded, test_size=0.2, random_state=42)\n",
    "print(\"training and testing data\")\n",
    "# Adjusting input shapes for LSTM based on FFT features\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=input_shape, return_sequences=True),\n",
    "    LSTM(64),\n",
    "    Dense(len(le.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"compiled model\")\n",
    "# Train the model\n",
    "print(\"training model\")\n",
    "model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Second Window 3/2 Second Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motor Behavioral Task: (All conditions seen here)\n",
      "Motor Behavioral\n",
      "Training ITWT - A\n",
      "digit symbol task: (SIT)\n",
      "TWT_B training\n",
      "Training:TWT_B\n",
      "B1_T2: (WALK)\n",
      "trail making task: (SIT)\n",
      "Naughton Test: (WALK)\n",
      "B1_T1: (WALK)\n",
      "Training: TWT_A\n",
      "Motor behavioral task\n",
      "Training ITWT -B\n",
      "TNT\n",
      "TWT_A Training: (WALK)\n",
      "TM Comfortable Speed: (WALK)\n",
      "Naughton test\n",
      "B2_T1: (WALK)\n",
      "B1_TWT_A: (WALK)\n",
      "TWT_A training\n",
      "Training ITWT - B\n",
      "Training:TWT_A\n",
      "TWT_B Training: (WALK)\n",
      "Naughton\n",
      "B2_TWT_A: (WALK)\n",
      "SOT: (STAND)\n",
      "Montreal Cognitive Assessment: (SIT)\n",
      "HR Recovery: (STAND or SIT)\n",
      "B1_TWT_B: (WALK)\n",
      "B2_T2: (WALK)\n",
      "Naughton Task\n",
      "TM comfortable speed\n",
      "Training: TWT_B\n",
      "B2_TWT_B: (WALK)\n",
      "segments in suitable format\n",
      "labels encoded\n",
      "comiling model\n",
      "training model\n",
      "Epoch 1/10\n",
      "23335/23335 [==============================] - 1324s 57ms/step - loss: 1.8501 - accuracy: 0.3872 - val_loss: 1.3316 - val_accuracy: 0.5344\n",
      "Epoch 2/10\n",
      "23335/23335 [==============================] - 4629s 198ms/step - loss: 1.1433 - accuracy: 0.5951 - val_loss: 0.9908 - val_accuracy: 0.6553\n",
      "Epoch 3/10\n",
      "23335/23335 [==============================] - 1315s 56ms/step - loss: 0.9068 - accuracy: 0.6731 - val_loss: 0.8299 - val_accuracy: 0.6947\n",
      "Epoch 4/10\n",
      "23335/23335 [==============================] - 1444s 62ms/step - loss: 0.7692 - accuracy: 0.7187 - val_loss: 0.7437 - val_accuracy: 0.7202\n",
      "Epoch 5/10\n",
      "23335/23335 [==============================] - 1480s 63ms/step - loss: 0.6802 - accuracy: 0.7483 - val_loss: 0.6542 - val_accuracy: 0.7592\n",
      "Epoch 6/10\n",
      "23335/23335 [==============================] - 2423s 104ms/step - loss: 0.6125 - accuracy: 0.7720 - val_loss: 0.5866 - val_accuracy: 0.7834\n",
      "Epoch 7/10\n",
      "23335/23335 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.7874"
     ]
    }
   ],
   "source": [
    "activity_segments = segment_activities(96, 12)\n",
    "model = fit_model(activity_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Second Window 1/2 Second Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motor Behavioral Task: (All conditions seen here)\n",
      "Motor Behavioral\n",
      "Training ITWT - A\n",
      "digit symbol task: (SIT)\n",
      "TWT_B training\n",
      "Training:TWT_B\n",
      "B1_T2: (WALK)\n",
      "trail making task: (SIT)\n",
      "Naughton Test: (WALK)\n",
      "B1_T1: (WALK)\n",
      "Training: TWT_A\n",
      "Motor behavioral task\n",
      "Training ITWT -B\n",
      "TNT\n",
      "TWT_A Training: (WALK)\n",
      "TM Comfortable Speed: (WALK)\n",
      "Naughton test\n",
      "B2_T1: (WALK)\n",
      "B1_TWT_A: (WALK)\n",
      "TWT_A training\n",
      "Training ITWT - B\n",
      "Training:TWT_A\n",
      "TWT_B Training: (WALK)\n",
      "Naughton\n",
      "B2_TWT_A: (WALK)\n",
      "SOT: (STAND)\n",
      "Montreal Cognitive Assessment: (SIT)\n",
      "HR Recovery: (STAND or SIT)\n",
      "B1_TWT_B: (WALK)\n",
      "B2_T2: (WALK)\n",
      "Naughton Task\n",
      "TM comfortable speed\n",
      "Training: TWT_B\n",
      "B2_TWT_B: (WALK)\n",
      "segments in suitable format\n",
      "labels encoded\n",
      "comiling model\n",
      "training model\n",
      "Epoch 1/10\n",
      "17589/17589 [==============================] - 370s 21ms/step - loss: 1.7460 - accuracy: 0.4177 - val_loss: 1.4398 - val_accuracy: 0.5023\n",
      "Epoch 2/10\n",
      "17589/17589 [==============================] - 368s 21ms/step - loss: 1.3162 - accuracy: 0.5432 - val_loss: 1.2408 - val_accuracy: 0.5662\n",
      "Epoch 3/10\n",
      "17589/17589 [==============================] - 368s 21ms/step - loss: 1.1432 - accuracy: 0.5993 - val_loss: 1.0955 - val_accuracy: 0.6163\n",
      "Epoch 4/10\n",
      "17589/17589 [==============================] - 361s 21ms/step - loss: 1.0366 - accuracy: 0.6335 - val_loss: 1.0441 - val_accuracy: 0.6259\n",
      "Epoch 5/10\n",
      "17589/17589 [==============================] - 354s 20ms/step - loss: 0.9628 - accuracy: 0.6568 - val_loss: 0.9682 - val_accuracy: 0.6561\n",
      "Epoch 6/10\n",
      "17589/17589 [==============================] - 355s 20ms/step - loss: 0.9076 - accuracy: 0.6758 - val_loss: 0.9460 - val_accuracy: 0.6636\n",
      "Epoch 7/10\n",
      "17589/17589 [==============================] - 1878s 107ms/step - loss: 0.8637 - accuracy: 0.6894 - val_loss: 0.9013 - val_accuracy: 0.6815\n",
      "Epoch 8/10\n",
      "17589/17589 [==============================] - 365s 21ms/step - loss: 0.8299 - accuracy: 0.7014 - val_loss: 0.8888 - val_accuracy: 0.6817\n",
      "Epoch 9/10\n",
      "17589/17589 [==============================] - 365s 21ms/step - loss: 0.8027 - accuracy: 0.7103 - val_loss: 0.8696 - val_accuracy: 0.6944\n",
      "Epoch 10/10\n",
      "17589/17589 [==============================] - 365s 21ms/step - loss: 0.7777 - accuracy: 0.7177 - val_loss: 0.8818 - val_accuracy: 0.6842\n",
      "5497/5497 [==============================] - 31s 6ms/step - loss: 0.8829 - accuracy: 0.6835\n"
     ]
    }
   ],
   "source": [
    "activity_segments = segment_activities()\n",
    "model = fit_model(activity_segments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
